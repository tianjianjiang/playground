# Research Interests
## Paper Collections
* Qiuchi Li, Sagar Uprety, Benyou Wang, and Dawei Song. 2018. Quantum-Inspired Complex Word Embedding. In Proceedings of the 4th Workshop on Representation Learning for NLP, pages 50–57. Association for Computational Linguistics.
* Hongyu Gong, Suma Bhat, and Pramod Viswanath. 2018. Embedding Syntax and Semantics of Prepositions via Tensor Decomposition. In Proceedings of NAACL 2018, pages 896–906, Stroudsburg, PA, USA. Association for Computational Linguistics.
* Chiheb Trabelsi, Olexa Bilaniuk, Ying Zhang, Dmitriy Serdyuk, Sandeep Subramanian, Joao Felipe Santos, Soroush Mehri, Negar Rostamzadeh, Yoshua Bengio, and Christopher J Pal. 2018. Deep Complex Networks. In arXiv preprint arXiv:1705.09792
* Zi Yin and Yuanyuan Shen. 2018. On the dimensionality of word embedding. In Proceedings of the 32nd International Conference on Neural Information Processing Systems
* Tian, K., Zhang, T. & Zou, J.. 2018. CoVeR: Learning Covariate-Specific Vector Representations with Tensor Decompositions. Proceedings of the 35th International Conference on Machine Learning, in PMLR 80:4926-4935
* Arjovsky, M., Shah, A. & Bengio, Y.. 2016. Unitary Evolution Recurrent Neural Networks. Proceedings of The 33rd International Conference on Machine Learning, in PMLR 48:1120-1128
* Danihelka, I., Wayne, G., Uria, B., Kalchbrenner, N. & Graves, A.. 2016. Associative Long Short-Term Memory. Proceedings of The 33rd International Conference on Machine Learning, in PMLR 48:1986-1994
* Théo Trouillon, Johannes Welbl, Sebastian Riedel, Éric Gaussier, and Guillaume Bouchard. 2016. Complex embeddings for simple link prediction. In Proceedings of ICML 2016, pages 2071–2080.
